{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://cog-oaxatpknic6wq.openai.azure.com/\"\n",
    "openai.api_version = \"2023-03-15-preview\"\n",
    "openai.api_key = \"a4afc38d3a6246d3b855a8adcca0d0f1\"\n",
    "\n",
    "#endpoint = \"https://gptkb-oaxatpknic6wq.search.windows.net\"\n",
    "\n",
    "model_name = \"gpt-35-turbo\"\n",
    "deployment_name =\"chat\"\n",
    "prompt = \"Who is Charles Babbage?\"\n",
    "\n",
    "azure_credential = DefaultAzureCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = {\n",
    "    \"source1.txt\" : \"data\\Azure HDInsight for Apache Spark 3.3 is now available for public preview _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source2.txt\" : \"data\\Azure VMware Solution now available in North Switzerland _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source3.txt\" : \"data\\General availability_ Azure HX Virtual Machines for HPC _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source4.txt\" : \"data\\General availability_ Query performance insights for Azure Database for PostgreSQL â€“ Flexible Server _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source5.txt\" : \"data\\Microsoft Azure Load Testing - additional Azure components for server-side monitoring _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source6.txt\" : \"data\\Public preview_ Add-on and node image in AKS release tracker _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source7.txt\" : \"data\\Public preview_ Assess impact of service retirements workbook template in Azure Advisor _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source8.txt\" : \"data\\Public Preview_ Azure Virtual Desktop Insights Powered by the Azure Monitor Agent _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source9.txt\" : \"data\\Public preview_ Confidential Virtual Machines (VM) support in Azure Virtual Desktop _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source10.txt\" : \"data\\Public preview_ Custom Image Templates for Azure Virtual Desktop _ Azure updates _ Microsoft Azure.html\",\n",
    "    \"source11.txt\" : \"data\\Public Preview_ GraphQL resolvers for Azure Cosmos DB, Azure SQL in Azure API Management _ Azure updates _ Microsoft Azure.html\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# ChatGPT uses a particular set of tokens to indicate turns in conversations\n",
    "prompt_prefix = \"\"\"<|im_start|>system\n",
    "Assistant helps the company employees with their Microsoft Azure questions.\n",
    "Answer ONLY with the facts listed in the list of sources below. If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. If asking a clarifying question to the user would help, ask the question. \n",
    "Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. Use square brackets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
    "\n",
    "\n",
    "Sources:\n",
    "[source1.txt][source2.txt][source3.txt][source4.txt][source5.txt][source6.txt][source7.txt][source8.txt][source9.txt][source10.txt][source11.txt]\n",
    "\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "turn_prefix = \"\"\"\n",
    "<|im_start|>user\n",
    "\"\"\"\n",
    "\n",
    "turn_suffix = \"\"\"\n",
    "<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompt_history = turn_prefix\n",
    "\n",
    "history = []\n",
    "\n",
    "summary_prompt_template = \"\"\"Below is a summary of the conversation so far, and a new question asked by the user that needs to be answered by searching in a knowledge base. Generate a search query based on the conversation and the new question. Source names are not good search terms to include in the search query.\n",
    "\n",
    "Summary:\n",
    "{summary}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Search query:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching: Who is Charles Babbage?\n",
      "-------------------\n",
      "user: Who is Charles Babbage?\n",
      "-------------------\n",
      "assistant:  Charles Babbage was an English mathematician and inventor who is credited with inventing the first mechanical computer that eventually led to more complex designs. He was born on December 26, 1791, in London, England, and died on October 18, 1871, in Marylebone, London, England. Babbage was a polymath who made significant contributions to various fields, including mathematics, engineering, and computer science. He is best known for his work on the Analytical Engine\n",
      "\n",
      "-------------------\n",
      "Prompt:\n",
      "Who is Charles Babbage?\n"
     ]
    }
   ],
   "source": [
    "# Execute this cell multiple times updating user_input to accumulate chat history\n",
    "user_input = \"Who is Charles Babbage?\"\n",
    "\n",
    "# Exclude category, to simulate scenarios where there's a set of docs you can't see\n",
    "exclude_category = None\n",
    "\n",
    "if len(history) > 0:\n",
    "    completion = openai.Completion.create(\n",
    "        prompt = prompt ,\n",
    "        max_tokens = 10,\n",
    "        temperature = 0.9,\n",
    "        engine=deployment_name)\n",
    "    search = completion.choices[0].text\n",
    "else:\n",
    "    search = user_input\n",
    "\n",
    "# Alternatively simply use search_client.search(q, top=3) if not using semantic search\n",
    "print(\"Searching:\", search)\n",
    "print(\"-------------------\")\n",
    "filter = \"category ne '{}'\".format(exclude_category.replace(\"'\", \"''\")) if exclude_category else None\n",
    "\n",
    "completion = openai.Completion.create(\n",
    "    prompt = prompt ,\n",
    "    max_tokens = 100,\n",
    "    temperature = 0,\n",
    "    engine=deployment_name,\n",
    "    stop=[\"<|im_end|>\", \"<|im_start|>\"])\n",
    "\n",
    "prompt_history += user_input + turn_suffix + completion.choices[0].text + \"\\n<|im_end|>\" + turn_prefix\n",
    "history.append(\"user: \" + user_input)\n",
    "history.append(\"assistant: \" + completion.choices[0].text)\n",
    "\n",
    "print(\"\\n-------------------\\n\".join(history))\n",
    "print(\"\\n-------------------\\nPrompt:\\n\" + prompt)\n",
    "\n",
    "#print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c40b9fc8dfc687e53ddb074d322e19207ef9cf3db51c580aef67976913dea803"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
